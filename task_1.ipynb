{
 "cells": [
  {
   "cell_type": "raw",
   "id": "15ce47d2-0571-40b5-9428-2fe550b105ef",
   "metadata": {},
   "source": [
    "Задание 1 (25 б) Лемматизации текста\n",
    "\n",
    "Написать програмный модуль для лемматизации текста: лемматизировать текст и приписать леммам частеречные теги. Для решения задачи можно использовать данные, например, словарь oDict, разметку OpenCorpora и др. Можно использовать как русские, так и английские словари.\n",
    "\n",
    "Ввод: предложения вида \"токен1 токен2 ... токенN\" с расставленными знаками препинания, разделенные переносом строки. Из знаков препинания в предложениях могут содержаться только запятая, точка, вопросительный и восклицательный знаки.\n",
    "\n",
    "Вывод: Для каждого предложения из входных данных вывод в виде\n",
    " \"токен1{лемма1=тег1} токен2{лемма2= тег2} ... токенN{леммаN=тегN}\" \n",
    "без исходных знаков препинания. Разделитель между токенами ‒ пробел. При лемматизации буквы е и ё, а также написание с прописной/строчной буквы признаются равноправными. Частеречные теги должны быть приведены к следующему инвентарю: \n",
    "\tсуществительные (S), \n",
    "\tприлагательные (A), \n",
    "\tглаголы, в том числе причастия и деепричастия (V), \n",
    "\tпредлоги (PR), \n",
    "\tсоюзы (CONJ), \n",
    "\tсборная категория (ADV), включающая наречия, вводные слова, частицы, междометия.\n",
    "В упрощенном варианте приведены к следующему инвентарю: \n",
    "\tсуществительные (S), \n",
    "\tприлагательные (A), \n",
    "\tглаголы, в том числе причастия и деепричастия (V), \n",
    "\tсборная категория (ADV), включающая наречия, вводные слова, частицы, междометия, предлоги, союзы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c410b5-232f-4d95-9b51-abfc8dba7711",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m491.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=8eff6166be56651e38074c3bddd9c7a03ea36e7b3d0bcc3aea403a3c65c58637\n",
      "  Stored in directory: /Users/daniyar_issenov/Library/Caches/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a6ed6f-b924-47ca-bbdb-7397e690ed39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "import pymorphy2\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0322879-f7ff-42d7-8f37-edbb12847a72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary (text): \n",
    "    sentences = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', text)\n",
    "    clean_text = text.lower()\n",
    "    word_tokenize = clean_text.split()\n",
    "    stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n",
    "                  \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\",\n",
    "                  \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\",\n",
    "                  \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \n",
    "                  \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \n",
    "                  \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\n",
    "                  \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \n",
    "                  \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \n",
    "                  \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \n",
    "                  \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "    word2count = {}\n",
    "    for word in word_tokenize:\n",
    "        if word not in stop_words:\n",
    "            if word not in word2count.keys():\n",
    "                word2count[word] = 1\n",
    "            else:\n",
    "                word2count[word] += 1\n",
    "                \n",
    "    sent2score = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.split():\n",
    "            if word in word2count.keys():\n",
    "                if len(sentence.split(' ')) < 28 and len(sentence.split(' ')) > 9:\n",
    "                    if sentence not in sent2score.keys():\n",
    "                        sent2score[sentence] = word2count[word]\n",
    "                    else:\n",
    "                        sent2score[sentence] += word2count[word]           \n",
    "                \n",
    "    for key in word2count.keys():\n",
    "        word2count[key] = word2count[key] / max(word2count.values())\n",
    "\n",
    "    best_three_sentences = heapq.nlargest(3, sent2score, key=sent2score.get)\n",
    "    return best_three_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ebbf5a-2459-48e1-8d23-17debdf98dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for article1.txt:\n",
      "The proposed music \n",
      "plagiarism detection system should be a welcome news \n",
      "to the music industry\n",
      "The system receives as input a polyphonic \n",
      "music (PCM data) and outputs information of\n",
      "plagiarized music (music title, time, etc\n",
      "Then, it \n",
      "calculates the melody similarity to the music in the \n",
      "database and retrieves the plagiarized music\n",
      "\n",
      "\n",
      "Summary for article2.txt:\n",
      "Similar melody searching is to find \n",
      "the melodies similar to a given query melody from a music database\n",
      "Section 3 discusses an in\u0002dexing method for efficient similar melody searching from melody databases\n",
      "For example, the following melody with a C major \n",
      "key in four-quarters time is described as a melody sequence of length 4, i\n",
      "\n",
      "\n",
      "Summary for article3.txt:\n",
      "In this we suggest a method for indexing the features extracted from every melody and a method for \n",
      "processing plagiarism detection by using the index\n",
      "The idea is that \n",
      "treating the time-frequency representation as a texture image we can extract features to build reliable music \n",
      "genre classification systems\n",
      "With our plagiarism detection system, composers can easily \n",
      "search for the melodies similar to their ones from music databases\n",
      "\n",
      "\n",
      "Summary for article4.txt:\n",
      "Every year ,vast numbers of new music \n",
      "tracks are released globally, and questionable similarities exist in some sections of music tracks\n",
      "Sampling Plagiarism\n",
      "The term sampling describes the re-use of recorded sounds or music excerpts in another song\n",
      "In this project Each audio file is fingerprinted, The fingerprints \n",
      "from the unknown sample are matched against a large set of fingerprints derived from the music database\n",
      "\n",
      "\n",
      "Summary for article5.txt:\n",
      "Melody plagiarism inspection can be done with basically the same approach, \n",
      "since means to identify and evaluate melodic similarity are required\n",
      "The main difference is, that QbH searches \n",
      "across extensive databases while plagiarism detection concentrates on one single comparison, which has to be \n",
      "more precise\n",
      "Thus, melody plagiarism is a gray area, where it is hard to discern copying \n",
      "from citation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_files = [\"article1.txt\", \"article2.txt\", \"article3.txt\", \"article4.txt\", \"article5.txt\"]\n",
    "\n",
    "for input_file in input_files:\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        summary = generate_summary(text)\n",
    "        print(f\"Summary for {input_file}:\")\n",
    "        for sentence in summary:\n",
    "            print(sentence)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35888b5e-1dd9-47c8-a565-d57c526a498c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m morph \u001b[38;5;241m=\u001b[39m pymorphy2\u001b[38;5;241m.\u001b[39mMorphAnalyzer()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/analyzer.py:224\u001b[0m, in \u001b[0;36mMorphAnalyzer.__init__\u001b[0;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_type_orig \u001b[38;5;241m=\u001b[39m result_type\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_char_substitutes(char_substitutes)\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_units(units)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/analyzer.py:235\u001b[0m, in \u001b[0;36mMorphAnalyzer._init_units\u001b[0;34m(self, units_unbound)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m unit \u001b[38;5;129;01min\u001b[39;00m item[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 235\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(unit), \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_units\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_unit(item[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/analyzer.py:246\u001b[0m, in \u001b[0;36mMorphAnalyzer._bound_unit\u001b[0;34m(self, unit)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_bound_unit\u001b[39m(\u001b[38;5;28mself\u001b[39m, unit):\n\u001b[0;32m--> 246\u001b[0m     unit \u001b[38;5;241m=\u001b[39m unit\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    247\u001b[0m     unit\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/units/base.py:35\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit.clone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclone\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_params())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/units/base.py:76\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m---> 76\u001b[0m         (key, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[1;32m     77\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pymorphy2/units/base.py:70\u001b[0m, in \u001b[0;36mBaseAnalyzerUnit._get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m---> 70\u001b[0m args, varargs, kw, default \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetargspec(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(args[\u001b[38;5;241m1\u001b[39m:])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1702ea-9b4c-4c0d-b865-e42744d35043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
